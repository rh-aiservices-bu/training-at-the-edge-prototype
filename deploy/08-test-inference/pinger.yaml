
# deployed_model_name = "fraud"
# rest_url = "http://modelmesh-serving:8008"
# infer_url = f"{rest_url}/v2/models/{deployed_model_name}/infer"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-pinger
  labels:
    app: model-pinger
spec:
  replicas: 1
  revisionHistoryLimit: 3
  selector:
    matchLabels:
      app: model-pinger
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 100%
  template:
    metadata:
      labels:
        app: model-pinger
    spec:
      containers:
      - name: pinger
        image: quay.io/modh/odh-generic-data-science-notebook@sha256:f1c285f88f37abb0d54efc1941f349dfed824896568bcd359770e15d78fdb9f9
        command:
        - python
        - -u
        - /ping_model.py
        env:
        - name: MM_SERVING_HOST
          value: modelmesh-serving:8033
        - name: MM_MODEL_NAME
          value: ansible-wisdom-v06
        - name: SLEEP_TIME
          value: "2"
        resources:
          limits:
            cpu: "0.2"
            memory: 256Mi
        volumeMounts:
        - name: pinger-config
          subPath: ping_model.py
          mountPath: /ping_model.py
      imagePullSecrets:
      - name: watson-runtime-registry-secret
      volumes:
      - name: pinger-config
        configMap:
          name: model-pinger





































---
apiVersion: v1
kind: ConfigMap
metadata:
  name: model-pinger
data:
  ping_model.py: |
    import os
    import time
    from datetime import datetime

    deployed_model_name = "fraud-latest"
    rest_url = "http://modelmesh-serving:8008"
    infer_url = f"{rest_url}/v2/models/{deployed_model_name}/infer"

    import requests

    def rest_request(data):
        json_data = {
            "inputs": [
                {
                    "name": "dense_input",
                    "shape": [1, 5],
                    "datatype": "FP32",
                    "data": data
                }
            ]
        }

        response = requests.post(infer_url, json=json_data)
        response_dict = response.json()
        return response_dict['outputs'][0]['data']


    MM_SERVING_HOST = os.environ.get("MM_SERVING_HOST", "modelmesh-serving:8033")
    MM_MODEL_NAME = os.environ.get("MM_MODEL_NAME", "ansible-model-pinger")

    SLEEP_TIME = os.environ.get("SLEEP_TIME", "3")
    SLEEP_TIME = int(SLEEP_TIME)


    while True:
      now = datetime.now()
      time_string = now.strftime("%Y-%m-%d %H:%M:%S")

      print("--------------------------------------")
      print("Sending Request at",time_string)
      # print("MM_SERVING_HOST="+MM_SERVING_HOST)
      # print("MM_MODEL_NAME="+MM_MODEL_NAME)
      # print("PROMPT="+PROMPT)
      # print("CONTEXT="+CONTEXT)

      start = time.time()
      try:
        data = [0.3111400080477545, 1.9459399775518593, 1.0, 0.0, 0.0]
        prediction = rest_request(data)
        prediction

        threshhold = 0.995

        if (prediction[0] > threshhold):
            print('fraud')
        else:
            print('not fraud')

        # result = client.AnsiblePredict(request,
        #   metadata=(
        #     ("mm-vmodel-id", MM_MODEL_NAME),
        #   ),
        #   timeout=10
        # )

        # print(f"Generated something in {time.time() - start}s")

      except Exception as e:
        print(f"Errored after {time.time() - start}s: {e}")


      time.sleep(SLEEP_TIME)